[{"categories":["文献阅读"],"content":"简介 On-Off sketch是一个做persisence estimation和finding persistent items的算法。根据论文的介绍，这是第一个专门处理persistence esimation问题的算法，在finding persistent items方面，相比Small-Space和PIE也有着更好的表现。 我读了整篇论文，但是数学证明方面有一些地方没有看懂。所以本文只是对On-Off Sketch算法的过程和实验结果的分析进行描述。 ","date":"2020-11-30","objectID":"/on-off-sketch/:1:0","tags":["persistence","sketch"],"title":"On-Off Sketch","uri":"/on-off-sketch/"},{"categories":["文献阅读"],"content":"Persistence Persistence是一个类似frequncy, cardinality, quantile的数据特征(characteristic)。它的定义如下： Given an item $e$ and a data stream with $T$ non-overlapping and contiguous time windows, the persistence of $e$ is defined as the number of time windows where $e$ appears. ","date":"2020-11-30","objectID":"/on-off-sketch/:2:0","tags":["persistence","sketch"],"title":"On-Off Sketch","uri":"/on-off-sketch/"},{"categories":["文献阅读"],"content":"Persistence Estimation 如前文所述，论文中说没有专门在这个方面设计算法的。但是有一些先前用在别的问题上的算法可以去做persistence estimation。 ","date":"2020-11-30","objectID":"/on-off-sketch/:3:0","tags":["persistence","sketch"],"title":"On-Off Sketch","uri":"/on-off-sketch/"},{"categories":["文献阅读"],"content":"Prior Work 使用Bloom Filter+Count-Min sketch (CM sketch)。 Bloom Filter是用来处理membership问题的。CM Sketch是用来处理frequency问题的。这个两个算法结合是一种简单的处理persistence estimation的方式。假设当前item $e$到来，算法描述如下。 在每个时间窗口结束时，设置Bloom Filter所有位为0。不改变CM sketch。 CM sketch初始化所有位为0。 判断$e$是否在Bloom Filter中。如果在，说明当前时间窗口$e$已经出现过，不做处理；如果不在，就把$e$插入到Bloom Filter中，执行下一步。 把$e$插入到CM sketch中。 理想状况下，这个算法可以实现persistence estimation。通过Bloom Filter保证一个时间窗口一个item最多被记录一次，通过CM Sketch在所有时间窗口计算persistence值。但是同样，它有很大的局限性。 Bloom Filter会出现假阳性 (false positive)。这个时间窗口中没有出现的item被错误地认为是已经出现过。 CM sketch的哈希碰撞会导致persistence被严重高估。如下图，3个item被映射到同一位置，本来3个item的persistence应该各增加1，现在各增加了3。 Overestimation 对此我们希望停止使用Bloom Filter，并保证每一个CM Sketch的计数器在一个时间窗口只增加1。 ","date":"2020-11-30","objectID":"/on-off-sketch/:3:1","tags":["persistence","sketch"],"title":"On-Off Sketch","uri":"/on-off-sketch/"},{"categories":["文献阅读"],"content":"On-Off Sketch: Persistence Estimation 数据结构 On-Off Sketch提出了新的数据结构。On-Off sketch由$d$个数组组成，每一个数组包括$l$个计数器。其中每个计数器都有一个状态域 (state field)，有On和Off两个状态。第$i$个数组的第$j$个计数器表示为$C_i[j]$。 在每个时间窗口最后，把所有的state field设置为On。 添加item 添加item $e_i$到On-Off sketch。用$d$个哈希函数计算哈希值，把$e_i$映射到$d$个计数器$C_j[h_j(e_i)]$中。这$d$个计数器每一个都可能有两种情况： 计数器的state为On。把计数器值增加1，把state变成Off。 计数器的state为Off。说明这个计数器在当前时间窗口被访问过 。所以不再改变计数器。 查询 和CM sketch类似，对要查询的item $e_i$做$d$个哈希找到相应计数器，然后取其中的最小值。把persistence的估计值表示为$\\hat{p_i}$，也就是 $$ \\hat{p_i} = min_{1 \\le j \\le d} \\left(C_j[h_j(e_i)] \\right) $$ 算法分析 这个算法达成了前面我们说的两个目标。 避免使用Bloom Filter，不会出现它产生的假阳性问题，从而不会有item的persistence被低估，只会被高估，只会产生单边错误 (one sided errors)。 每一个计数器在一个时间窗口内只能增加1，避免了CM sketch哈希碰撞导致高估过多的情况。 将每一个数组的计数器个数$l$、数组个数$d$表示为 $$ \\begin{aligned} l\u0026=e/\\epsilon \\\\ d\u0026=ln \\left( 1/\\delta \\right) \\end{aligned} $$ 根据论文的分析，算法的时间复杂度为$O \\left(ln \\left(1/\\delta \\right) \\right)$，空间复杂度为$O \\left( \\left( 1/\\epsilon \\right) \\right) ln(1/\\delta)$。此外可以证明，On-Off sketch的误差一定小于CM sketch。 ","date":"2020-11-30","objectID":"/on-off-sketch/:3:2","tags":["persistence","sketch"],"title":"On-Off Sketch","uri":"/on-off-sketch/"},{"categories":["文献阅读"],"content":"Finding Persistent Items ","date":"2020-11-30","objectID":"/on-off-sketch/:4:0","tags":["persistence","sketch"],"title":"On-Off Sketch","uri":"/on-off-sketch/"},{"categories":["文献阅读"],"content":"Prior work 对于这个问题，先前的工作有Small Space和PIE两个。这两个可以看以前的文章。 简述这两个算法的缺点： 大量空间存储的都是non-persistent items，造成严重浪费。 Small Space错误控制得不好。想要更精确就要花费大量的空间。 PIE相比之下空间需求很大。 PIE通过Raptor code恢复item ID需要用到矩阵乘法，速度慢。 ","date":"2020-11-30","objectID":"/on-off-sketch/:4:1","tags":["persistence","sketch"],"title":"On-Off Sketch","uri":"/on-off-sketch/"},{"categories":["文献阅读"],"content":"On-Off Sketch: Finding Persistent Items 为了避免出现上述问题，On-Off sketch的核心技术是通过persistence识别items，并且只储存persistent items的ID。 数据结构 由两部分组成。 一个由$l$个计数器组成的数组。第$i$个计数器表示为$C_1[i]$。这个数组使用一个哈希函数$h_1 \\left( . \\right)$，把每个item映射到数组的一个计数器中。 一个由$l$个桶 (bucket) 构成的数组组成，第一部分中的每一个计数器对应一个桶。例如$B[i]$对应$C_1{i}$。每一个桶含有$w$个键值对 (key-value (KV) pairs)，键是item ID，值是一个计数器。这个计数器用$B[i][e_j]$表示。每个计数器也有它自己的state field。 初始化每一个计数器的state field为On，所有计数器值为0。 插入 要插入item $e_i$，先判断$e_i$是否已经在桶$B[h_1(e_i)]$中。 如果在桶中，且$B[h_1(e_i)][e_i]$的state为On，把$B[h_1(e_i)][e_i]$增加1，state设为Off；如果$B[h_1(e_i)][e_i]$的state为Off，不做操作。 如果不在，且$C_1[h_1(e_i)]$的state为On，把$C_1[h_1(e_i)]$增加1，state设为Off。 如果此时$C_1[h_1(e_i)]\u003eB[h_1(e_i)]^{min}$，就交换$C_1[h_1(e_i)]$和桶中值最小的那个计数器的值以及state field。然后把$B[h_1(e_i)]^{min}$对应的item ID换成$e_i$。 如果此时$C_1[h_1(e_i)]\\le B[h_1(e_i)]^{min}$，不做操作。 如果不在，且$C_1[h_1(e_i)]$的state为Off，不做操作。 在每个时间窗口最后，把所有计数器的state field设为On。 查询persistent items 遍历所有桶，报告计数器的值大于给定阈值的item ID。 算法分析 只用了一个计数器数组和它们附加的桶。减小数组的数量可以提升吞吐量（关于吞吐量的内容我还不太明白原因）。使用附加的桶，可以做到分离persistent items和non-persistent items，并且只记录item iD。如果一个item的persistence足够高，那它就不会被替换出去，也避免了哈希碰撞的可能。 设$l=2/\\epsilon, w=1$，算法的空间复杂度为$O(1/\\epsilon)$。 ","date":"2020-11-30","objectID":"/on-off-sketch/:4:2","tags":["persistence","sketch"],"title":"On-Off Sketch","uri":"/on-off-sketch/"},{"categories":["文献阅读"],"content":"优化 使用SIMD进行加速。比如上面判断是否已经在桶中，就可以用SIMD进行并行匹配，加速这个过程。同样还是那个算法的比较过程，也可以加速。论文中特意提到Small Space和PIE没有顺序访问操作，大多只是读写一项内容 (read or write one item)，所以不能使用SIMD指令进行加速。 ","date":"2020-11-30","objectID":"/on-off-sketch/:5:0","tags":["persistence","sketch"],"title":"On-Off Sketch","uri":"/on-off-sketch/"},{"categories":["文献阅读"],"content":"结果分析 基本全面优于先前的工作。论文的图就不放了。这里多说一下参数设置对实验的影响结果。 ","date":"2020-11-30","objectID":"/on-off-sketch/:6:0","tags":["persistence","sketch"],"title":"On-Off Sketch","uri":"/on-off-sketch/"},{"categories":["文献阅读"],"content":"Persistence Estimation AAE (Average Absolute Error) 随着内存的增加，最优的$d$值也在增大。当内存比较小的时候，更大的$d$会造成AAE增大。但是随着内存的增加，AAE也会快速下降。 Insertion Throughput 内存的增大和$d$的增大会造成吞吐量的下降（这里内存增大为什么会影响吞吐量下降不太明白）。$d$对吞吐量影响更大，因为$d$变大代表更多的内存访问。 ","date":"2020-11-30","objectID":"/on-off-sketch/:6:1","tags":["persistence","sketch"],"title":"On-Off Sketch","uri":"/on-off-sketch/"},{"categories":["文献阅读"],"content":"Finding Persistent Items Error 有足够内存的条件下，$w$增加，AAE和FNR (false negative rate) 往往会下降。论文里还有一段关于\"randomness\"和$w, l$对AAR, FNR, FPR (false positive rate)的影响，但是我没有看明白，在这里放上原文。 With smaller $w$, the $l$ increases, and the randomness of also increases (注：原文如此，没懂). When the memory is too small, such randomness can reduce FPR because there are often some buckets whose degree of overestimation is small, so the AAE and FNR decrease. When there is enough memory, randomness increases FPR because there are more buckets whose degree of overestimation is too high, so the AAE and FNR increase. Insertion Throughput $w$提高，吞吐量会降低。但是由于内存访问次数少，就算$w$比较大，吞吐量仍然比较高。可见这里$w$的选取就是精确度和吞吐量之间的trade-off。 ","date":"2020-11-30","objectID":"/on-off-sketch/:6:2","tags":["persistence","sketch"],"title":"On-Off Sketch","uri":"/on-off-sketch/"},{"categories":["文献阅读"],"content":"简介 PIE算法使用Space-Time Bloom Filter(STBF)和Raptor Code，寻找persistent items。 我只读了算法的过程，数学证明和其他内容没有看。 ","date":"2020-11-29","objectID":"/pie/:1:0","tags":["sketch","persistence"],"title":"PIE算法","uri":"/pie/"},{"categories":["文献阅读"],"content":"Space-Time Bloom Filter STBF是Bloom Filter的扩展。Bloom Filter是$m$ bits，STBF就是$m$个cell。PIE中STBF的一个cell包含3部分内容： 1 bit的标志位$C_{iF}$。 0代表cell未使用或者发生冲突。 1代表cell已经被使用。 $r$ bits的Raptor Code $C_{iR}$。 用一个特定的哈希函数计算的$p$ bits的hash-print $C_{iP}$。 和Bloom Filter一样，STBF使用$k$个哈希函数做映射。如果有两个item被映射到了同一个cell（发生了冲突），那么把$C_{iF}$置0，$C_{iR}$和$C_{iP}$所有位置1。 ","date":"2020-11-29","objectID":"/pie/:2:0","tags":["sketch","persistence"],"title":"PIE算法","uri":"/pie/"},{"categories":["文献阅读"],"content":"Raptor Code Raptor code最重要的优势是对一个长度为$l$ bits的item ID，我们只需要存储$r$ bits （$r$比$l$小很多）的Raptor code就可以恢复出原本的item ID。 这个从原理上来说其实并不复杂，主要方式就是矩阵乘法。把item ID看作是$l \\times 1$的向量，选取一个$r \\times l$的矩阵 $$\rA =\r\\begin{bmatrix} a_{i1}^1 \u0026 a_{i1}^2 \u0026 \\cdots \u0026 a_{i1}^l \\\\\ra_{i2}^1 \u0026 a_{i2}^2 \u0026 \\cdots \u0026 a_{i2}^l \\\\\r\\vdots \u0026 \\vdots \u0026 \u0026 \\vdots \\\\\ra_{ir}^1 \u0026 a_{ir}^2 \u0026 \\cdots \u0026 a_{ir}^l \\\\\r\\end{bmatrix}\r$$\r\r$$\rA \\cdot\r\\begin{bmatrix} I_1^e \\\\ I_2^e \\\\ \\vdots \\\\ I_l^e \\\\ \\end{bmatrix} =\r\\begin{bmatrix} R_{i1}^e \\\\ R_{i2}^e \\\\ \\vdots \\\\ R_{ir}^e \\end{bmatrix}\r$$\r","date":"2020-11-29","objectID":"/pie/:3:0","tags":["sketch","persistence"],"title":"PIE算法","uri":"/pie/"},{"categories":["文献阅读"],"content":"PIE算法过程 PIE算法分为两个阶段： Recording Phase Identification Phase ","date":"2020-11-29","objectID":"/pie/:4:0","tags":["sketch","persistence"],"title":"PIE算法","uri":"/pie/"},{"categories":["文献阅读"],"content":"Recording Phase 这个阶段用来记录各个时间窗口出现的item。每一个时间窗口都要构建一个STBF来做记录。这些STBF应该用的都是相同的$k$个哈希函数。 假设当前时间窗口为$t_i$，接收到了item $e$。 用$e$的ID计算$r$-bit的Raptor code和$p$-bit的hash-print。 用STBF的$k$个哈希函数计算要映射的cell。 检查这些cell是空的(empty)，还是已经被一个item使用的(singleton)，还是已经发生冲突的(collided)。 如果是空的，就把三个数值添加进去。标志位设为1之后，这个cell的状态就变成了singleton。 如果已经被使用，检查储存在cell中的这个项目的hash-print和$e$的是否匹配。如果匹配不需要做其他操作；如果不匹配就要把cell的状态变成collided了，做法参照前文STBF的内容。 如果已经发生冲突，不需要做其他操作。 ","date":"2020-11-29","objectID":"/pie/:4:1","tags":["sketch","persistence"],"title":"PIE算法","uri":"/pie/"},{"categories":["文献阅读"],"content":"Identification Phase 这个过程用来找persistent items。 经过$T$个时间窗口，就建立了$T$个STBF。下面根据论文给出的例子讲解。 假设一个STBF长度为$m$-bit，新定义cell line，包含$STBF_1[x], STBF_2[x], \\dots , STBF_T[x]$，其中$1 \\le x \\le m$。 下面对cell line进行处理。 Cell Line Processing 丢弃cell line中所有为空(empty)和冲突(collide)的cell。 按照hash-print为cell line中剩下的进行分组(group)。hash-print相同的分为一组。可以看上面的图，颜色相同的在一个group中。图中圈出的cell line一共有3组。这里可能会遇到hash-print碰撞导致不相同的item被分到了一组，这样的group称为mingled groups。我们将在Mingled groups讨论这一情况。 将第$x$个cell line的groups和前面$x-1$个cell lines的groups比较，合并其中hash-print相同的组。 其中$x=1$的cell line不执行第3步，$x=2$到$x=m$的cell lines执行以上3步。 Recovering Item IDs 通过上面的步骤，对得到的groups计算item ID。这一步好像没有详细说明是如何选取Raptor code进行计算的（随机选一个item的还是用其他方法取得的）。因为如果是mingled groups，可能会出现group中两个item的hash-print相同而Raptor code不同的情况。 恢复出item ID后进行两步验证，确定item ID是否正确。 计算恢复出的item ID的hash-print，与group中的hash-prints比较是否相等。 （通过第一步验证后）使用$k$个哈希函数计算恢复的ID会被映射到的cell。 如果和group中的cell都冲突了，所有这些cell的Raptor code都相同，所有这些cell的hash-print都和恢复出的item ID的hash-print相同才算验证通过。 为了防止解释不清这里上原文吧。 For the recovered ID to pass the second test, unless the cells at these k locations in these STBFs are collided, the Raptor code fields of all these cells should be the same and the hash-prints of all these cells must match the hash-print of the recovered ID. 如果两步验证全都通过，那么这个恢复出的item ID有很大概率是正确的。 Mingled Groups 最后要解决一个group里有不同item的情况。 从$g_r=1$开始，临时把$g_r$个cells从group的$g$个cells中移除。用其他的$g-g_r$个cells恢复item ID。然后把$g_r$增加1，重新执行临时移除直到阈值$g_T$。一般$g_T$不会超过2. 从$g$个items中移除$g_r$个，也就是$\\left ( \\begin{smallmatrix} g \\\\ g_r \\end{smallmatrix} \\right)$种移除方式。当$g_r=1$时就是要做$g$次不同的移除，每次都重新恢复一个item ID再验证。 ","date":"2020-11-29","objectID":"/pie/:4:2","tags":["sketch","persistence"],"title":"PIE算法","uri":"/pie/"},{"categories":["文献阅读"],"content":"算法的问题 PIE的优势在于一个item的persistence越高，成功恢复item ID的概率也越大。但是它也有明显的缺陷。 使用Raptor code节省了空间，但是PIE要记录每一个时间窗口的所有不同的items(every distinct item)。其中大部分也都是non-persistent items，PIE浪费了大量空间在这些上面。 计算Raptor code要进行矩阵乘法，相比数据流的速度来说矩阵乘法太慢了。 ","date":"2020-11-29","objectID":"/pie/:5:0","tags":["sketch","persistence"],"title":"PIE算法","uri":"/pie/"},{"categories":["文献阅读"],"content":"简介 Small-Space算法主要用来做finding persistent item。 只读了算法过程，没有读参数的数值选择和数学证明。 Small-Space算法建立一个\"hash-based filter\"，通过给定哈希函数$h(d,t)$和阈值$\\tau$，对全体item做采样。可以工作在fixed window和sliding window上。 ","date":"2020-11-29","objectID":"/small-space/:1:0","tags":["sketch","persistence"],"title":"Small-Space算法","uri":"/small-space/"},{"categories":["文献阅读"],"content":"Fixed Window ","date":"2020-11-29","objectID":"/small-space/:2:0","tags":["sketch","persistence"],"title":"Small-Space算法","uri":"/small-space/"},{"categories":["文献阅读"],"content":"初始化与更新 $h(d,t)$的输出结果为$(0,1)$。值得说明的是，在同一个时间窗口$t$出现的相同item $d$，由于$h(d,t)$是相同的数，所以不会出现重复统计同一个时间窗口相同item的情况。 $d$代表一个item，$t$代表当前的时间窗口。$S$代表取样的item集合，$S$中一个项目的格式为$(d,n,t)$，$n$代表item $d$的persistence。这个数据结构可以看作是哈希表。 更新过程中，设当前时间窗口为$t$。 如果$d$已经在$S$中，表中的$d$记录的时间窗口$t_d\u003ct$，就把$d$的persistence增加1​，把$t_d$更新为$t$。 如果$d$不在$S$中，根据给定的阈值$\\tau$来决定是否对该item取样。如果要取样，就把$(d,1,t)$加入$S$中。 这里给定的阈值$\\tau$是一个accuracy和space assumption的trade-off。设定$\\tau$比较大，取样的就会更多，精确度更高，但是造成的空间开销也会更大。 这个算法使得经常出现的persistent items只要有一次被取样到了，后面的统计结果都是精确的。而不常出现的item被取样的概率会明显低于persistent item。 ","date":"2020-11-29","objectID":"/small-space/:2:1","tags":["sketch","persistence"],"title":"Small-Space算法","uri":"/small-space/"},{"categories":["文献阅读"],"content":"检测persistent items 这个算法没有仔细看，大致就是对统计的$n_d$加一点修正，与给定的persistent阈值$T$作比较。 ","date":"2020-11-29","objectID":"/small-space/:2:2","tags":["sketch","persistence"],"title":"Small-Space算法","uri":"/small-space/"},{"categories":["文献阅读"],"content":"Sliding Window 在滑动窗口中，我们只关注当前的窗口$c$到过去的$c-n+1$这$n$个窗口中的persistent items。取样的item集合也相应变为$S_{c-n+1}^{c}$。 ","date":"2020-11-29","objectID":"/small-space/:3:0","tags":["sketch","persistence"],"title":"Small-Space算法","uri":"/small-space/"},{"categories":["文献阅读"],"content":"初始化与更新 这个算法是fixed window版本的扩展。 举个例子说明这个算法是如何进行更新的。 假设$t_1$窗口接收了item $d_1$，且$h(d_1,t_1)\u003c\\tau$。根据第4行开始的伪代码，把$(d_1,t_1,1,t_1)$加入$S$中。 然后在前面的时间窗口中遍历寻找，是否有一个仍在过去$n$个时间窗口以内的窗口$t'$，有$(d_1,t',n_{d_1,t'},t_{d_1,t'})\\in S$。如果有的话，就把它的persistence增加1，并更新$t_{d_1,t'}$为$t_1$，代表最近出现的时间窗口。 **这个例子中假设在$n$个时间窗口中之前未曾出现$d_1$。**此时$S$中与$d_1$有关的只有$(d_1,t_1,1,t_1)$。 $t_2$窗口又接收了item $d_1$，执行第1步的操作。假设$(d_1,t_2,1,t_2)$也加入了$S$中。 找到了先前出现的$(d_1,t_1,1,t_1)$。然后更新为$(d_1,t_1,2,t_2)$。现在$S$中与$d_1$有关的有2个元组，$(d_1,t_1,2,t_2)$和$(d_1,t_2,1,t_2)$。 可以看到在滑动窗口的算法过程中，只要一个窗口出现了$d_1$，就要向$S$中新加入一个元组，还要更新之前的元组。 ","date":"2020-11-29","objectID":"/small-space/:3:1","tags":["sketch","persistence"],"title":"Small-Space算法","uri":"/small-space/"},{"categories":["文献阅读"],"content":"丢弃old items 更新算法使得丢弃超出$n$个时间窗口的old items非常简单。 检测persistent items $S_{cur}$代表找到当前$n$个时间窗口里，包含item $d$最早出现的时间窗口$t'$的元组集合。 ","date":"2020-11-29","objectID":"/small-space/:3:2","tags":["sketch","persistence"],"title":"Small-Space算法","uri":"/small-space/"},{"categories":["文献阅读"],"content":"算法的问题 这里只说fixed window。 在数据流中，绝大多数的item都是non-persistent item。而Small-Space在整个数据流中取样，导致保存的大多数都是non-persistent item，浪费了大量空间。 控制取样率的参数$\\tau$不能设置得太高，会加大空间消耗。但是设置得低会有更高的错误率。 使用哈希表作为数据结构，遇到哈希碰撞时会减小吞吐量。此外哈希表这个数据结构就需要比较大的空间。 ","date":"2020-11-29","objectID":"/small-space/:4:0","tags":["sketch","persistence"],"title":"Small-Space算法","uri":"/small-space/"},{"categories":null,"content":"显示效果测试 #include \u003ciostream\u003e int main() { std::cout \u003c\u003c \"Hello world!\" \u003c\u003c endl; return 0; } ==HIGHLIGHT== (not working) \r\r标题\r\r\r折叠内容\r\r$$ {\\color{red}E}={\\color{blue}mc^2} $$ 矩阵和其他环境必须写到一行，反斜线必须是双倍的。 $$ A = \\begin{bmatrix} a_{i1}^1 \u0026 a_{i1}^2 \u0026 \\cdots \u0026 a_{i1}^l \\\\ a_{i2}^1 \u0026 a_{i2}^2 \u0026 \\cdots \u0026 a_{i2}^l \\\\ \\vdots \u0026 \\vdots \u0026 \u0026 \\vdots \\\\ a_{ir}^1 \u0026 a_{ir}^2 \u0026 \\cdots \u0026 a_{ir}^l \\\\ \\end{bmatrix} $$ 图像大小建议： 斜体加上括号有可能不会被渲染！比如 *(123)* *（123）* 遇到过不被渲染的情况。所以尽量把括号写到外面。 ","date":"2020-11-21","objectID":"/%E6%98%BE%E7%A4%BA%E6%95%88%E6%9E%9C%E6%B5%8B%E8%AF%95/:0:0","tags":["test"],"title":"显示效果测试","uri":"/%E6%98%BE%E7%A4%BA%E6%95%88%E6%9E%9C%E6%B5%8B%E8%AF%95/"},{"categories":null,"content":"Hello This is the first post. ","date":"2020-11-21","objectID":"/hello/:0:0","tags":["test"],"title":"Hello","uri":"/hello/"},{"categories":null,"content":"一级目录 ","date":"2020-11-21","objectID":"/hello/:1:0","tags":["test"],"title":"Hello","uri":"/hello/"},{"categories":null,"content":"二级目录 ","date":"2020-11-21","objectID":"/hello/:2:0","tags":["test"],"title":"Hello","uri":"/hello/"},{"categories":null,"content":"三级目录 四级目录 五级目录 六级目录 ","date":"2020-11-21","objectID":"/hello/:2:1","tags":["test"],"title":"Hello","uri":"/hello/"}]